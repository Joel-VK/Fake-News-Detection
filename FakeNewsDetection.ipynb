{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers","metadata":{"id":"5AhupgyyQUbH","outputId":"a08bd940-baa8-4e3f-f736-7f72088e6c75","execution":{"iopub.status.busy":"2022-04-20T04:07:17.416845Z","iopub.execute_input":"2022-04-20T04:07:17.417536Z","iopub.status.idle":"2022-04-20T04:07:26.238838Z","shell.execute_reply.started":"2022-04-20T04:07:17.417445Z","shell.execute_reply":"2022-04-20T04:07:26.237811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch","metadata":{"execution":{"iopub.status.busy":"2022-04-20T04:07:26.241035Z","iopub.execute_input":"2022-04-20T04:07:26.242126Z","iopub.status.idle":"2022-04-20T04:07:33.438341Z","shell.execute_reply.started":"2022-04-20T04:07:26.242089Z","shell.execute_reply":"2022-04-20T04:07:33.437473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pytorch","metadata":{"id":"l9UMKhrKjEWf","outputId":"af958a99-c966-44cf-ac6c-8f0a9c95dcfa","execution":{"iopub.status.busy":"2022-04-20T04:07:33.440087Z","iopub.execute_input":"2022-04-20T04:07:33.440387Z","iopub.status.idle":"2022-04-20T04:07:43.642329Z","shell.execute_reply.started":"2022-04-20T04:07:33.440351Z","shell.execute_reply":"2022-04-20T04:07:43.640373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPU Test","metadata":{"id":"xNZzOcAmf_gL"}},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"id":"Sl1-BIrQgEco","outputId":"86012ec5-696b-43e8-bc7a-564f6f6ed684","execution":{"iopub.status.busy":"2022-04-20T04:07:43.645245Z","iopub.execute_input":"2022-04-20T04:07:43.645568Z","iopub.status.idle":"2022-04-20T04:07:45.179192Z","shell.execute_reply.started":"2022-04-20T04:07:43.645526Z","shell.execute_reply":"2022-04-20T04:07:45.178424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"id":"JLHKFvO8gOHB","outputId":"e24f63f8-5a5d-4103-b4fb-7a71af1c2e96","execution":{"iopub.status.busy":"2022-04-20T04:07:45.180396Z","iopub.execute_input":"2022-04-20T04:07:45.180649Z","iopub.status.idle":"2022-04-20T04:07:45.18822Z","shell.execute_reply.started":"2022-04-20T04:07:45.180604Z","shell.execute_reply":"2022-04-20T04:07:45.187536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data_loader","metadata":{"id":"4Kdo5EW0Qp-n"}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\n\nimport torch.nn.functional as F\nfrom transformers import BertModel\nimport random\nimport time\nimport os\nimport re\n\n# 预处理\ndef text_preprocessing(text):\n   \n    \n    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n\n    \n    text = re.sub(r'&amp;', '&', text)\n\n \n    text = re.sub(r'\\s+', ' ', text).strip()\n\n    return text\n\n\nclass FakeNewsDataset(Dataset):\n\n    def __init__(self, df, root_dir, image_transform, tokenizer, MAX_LEN):\n       \n        self.csv_data = df\n        self.root_dir = root_dir\n        self.image_transform = image_transform\n        self.tokenizer_bert = tokenizer\n        self.MAX_LEN = MAX_LEN\n\n    def __len__(self):\n        return self.csv_data.shape[0]\n    \n    def pre_processing_BERT(self, sent):\n\n        \n        input_ids = []\n        attention_mask = []\n        \n        encoded_sent = self.tokenizer_bert.encode_plus(\n            text=text_preprocessing(sent), \n            add_special_tokens=True,        \n            max_length=self.MAX_LEN,        \n            padding='max_length',           \n            # return_tensors='pt',          \n            return_attention_mask=True,    \n            truncation=True\n            )\n        \n        input_ids = encoded_sent.get('input_ids')\n        attention_mask = encoded_sent.get('attention_mask')\n        \n       \n        input_ids = torch.tensor(input_ids)\n        attention_mask = torch.tensor(attention_mask)\n        \n        return input_ids, attention_mask\n     \n        \n    def __getitem__(self, idx):\n\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = self.root_dir + self.csv_data['image_id'][idx] + '.jpg'\n        image = Image.open(img_name).convert(\"RGB\")\n        image = self.image_transform(image)\n        \n        text = self.csv_data['post_text'][idx]\n        tensor_input_id, tensor_input_mask = self.pre_processing_BERT(text)\n\n        label = self.csv_data['label'][idx]\n\n        if label == 'fake':\n            label = '1'\n        else:\n            label = '0'\n        label = int(label)\n        \n        label = torch.tensor(label)\n\n        sample = {\n                  'image_id'  :  image, \n                  'BERT_ip'   : [tensor_input_id, tensor_input_mask],\n                  'label'     :  label\n                  }\n\n        return sample","metadata":{"id":"LFMrDTzkPoVt","execution":{"iopub.status.busy":"2022-04-20T04:07:45.189539Z","iopub.execute_input":"2022-04-20T04:07:45.190243Z","iopub.status.idle":"2022-04-20T04:07:47.212444Z","shell.execute_reply.started":"2022-04-20T04:07:45.190205Z","shell.execute_reply":"2022-04-20T04:07:47.211726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{"id":"wnAzSrUZRBo7"}},{"cell_type":"code","source":"from importlib_metadata import re\nimport torch\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import models, transforms\nimport torch.nn as nn\nfrom transformers import BertModel\n\ndevice = torch.device(\"cuda\")\n\n\nclass TextEncoder(nn.Module):\n\n    def __init__(self, text_fc2_out=32, text_fc1_out=2742, dropout_p=0.4, fine_tune_module=False):\n\n        super(TextEncoder, self).__init__()\n        \n        self.fine_tune_module = fine_tune_module\n\n       \n        self.bert = BertModel.from_pretrained(\n                    'bert-base-uncased',\n#                     output_attentions = True, \n                    return_dict=True)\n\n        self.text_enc_fc1 = torch.nn.Linear(768, text_fc1_out)\n\n        self.text_enc_fc2 = torch.nn.Linear(text_fc1_out, text_fc2_out)\n\n        self.dropout = nn.Dropout(dropout_p)\n\n        self.fine_tune()\n        \n    def forward(self, input_ids, attention_mask):\n       \n\n       \n        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        # print(out['pooler_output'].shape)\n        x = self.dropout(\n            torch.nn.functional.relu(\n                self.text_enc_fc1(out['pooler_output']))\n        )    \n        \n        x = self.dropout(\n            torch.nn.functional.relu(\n                self.text_enc_fc2(x))\n        ) \n        \n        return x\n    \n    def fine_tune(self):\n        \n        for p in self.bert.parameters():\n            p.requires_grad = self.fine_tune_module\n            \n\n\nclass VisionEncoder(nn.Module):\n   \n    def __init__(self, img_fc1_out=2742, img_fc2_out=32, dropout_p=0.4, fine_tune_module=False):\n        super(VisionEncoder, self).__init__()\n        \n        self.fine_tune_module = fine_tune_module\n        \n      \n        vgg = models.vgg19(pretrained=True)\n        vgg.classifier = nn.Sequential(*list(vgg.classifier.children())[:1])\n        \n        self.vis_encoder = vgg\n\n        self.vis_enc_fc1 = torch.nn.Linear(4096, img_fc1_out)\n\n        self.vis_enc_fc2 = torch.nn.Linear(img_fc1_out, img_fc2_out)\n\n        self.dropout = nn.Dropout(dropout_p)\n\n        self.fine_tune()\n        \n    def forward(self, images):\n     \n        x = self.vis_encoder(images)\n\n        x = self.dropout(\n            torch.nn.functional.relu(\n                self.vis_enc_fc1(x))\n        )\n\n        x = self.dropout(\n            torch.nn.functional.relu(\n                self.vis_enc_fc2(x))\n        )\n\n        return x\n    \n    def fine_tune(self):\n       \n        for p in self.vis_encoder.parameters():\n            p.requires_grad = False\n\n        \n        for c in list(self.vis_encoder.children())[5:]:\n            for p in c.parameters():\n                p.requires_grad = self.fine_tune_module\n\n\nclass Text_Concat_Vision(torch.nn.Module):\n\n    def __init__(self,\n        model_params\n    ):\n        super(Text_Concat_Vision, self).__init__()\n        \n        self.text_encoder = TextEncoder(model_params['text_fc2_out'], model_params['text_fc1_out'], model_params['dropout_p'], model_params['fine_tune_text_module'])\n        self.vision_encode = VisionEncoder(model_params['img_fc1_out'], model_params['img_fc2_out'], model_params['dropout_p'], model_params['fine_tune_vis_module'])\n\n        self.fusion = torch.nn.Linear(\n            in_features=(model_params['text_fc2_out'] + model_params['img_fc2_out']), \n            out_features=model_params['fusion_output_size']\n        )\n        self.fc = torch.nn.Linear(\n            in_features=model_params['fusion_output_size'], \n            out_features=1\n        )\n        self.dropout = torch.nn.Dropout(model_params['dropout_p'])\n\n\n    #def forward(self, text, image, label=None):\n    def forward(self, text, image, label=None):\n\n        ## text to Bert\n        text_features = self.text_encoder(text[0], text[1])\n        ## image to vgg\n        image_features = self.vision_encode(image)\n\n        \n        combined_features = torch.cat(\n            [text_features, image_features], dim = 1\n        )\n\n        combined_features = self.dropout(combined_features)\n        \n        fused = self.dropout(\n            torch.relu(\n            self.fusion(combined_features)\n            )\n        )\n        \n        # prediction = torch.nn.functional.sigmoid(self.fc(fused))\n        prediction = torch.sigmoid(self.fc(fused))\n\n        prediction = prediction.squeeze(-1)\n\n        # prediction = prediction.cpu().detach().numpy()\n        \n        # for i in range(len(prediction)):\n        #     if prediction[i] > 0.5:\n        #         prediction[i] = 1.0\n        #     else:\n        #         prediction[i] = 0.0\n\n        # prediction = torch.tensor(prediction, dtype=torch.float32, requires_grad = False).to(device)\n        prediction = prediction.float()\n        \n        return prediction","metadata":{"id":"RJJtKDTfQfYH","execution":{"iopub.status.busy":"2022-04-20T04:07:47.214053Z","iopub.execute_input":"2022-04-20T04:07:47.214317Z","iopub.status.idle":"2022-04-20T04:07:47.240054Z","shell.execute_reply.started":"2022-04-20T04:07:47.214284Z","shell.execute_reply":"2022-04-20T04:07:47.238524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"id":"b6-5xw7sfuQW"}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport random\nimport time\nimport os\nimport re\nimport math\n\n\ndef train(model, loss_fn, optimizer, scheduler, train_dataloader, val_dataloader=None, epochs=4, evaluation=True, device='cpu', \n            param_dict_model=None, param_dict_opt=None, save_best=True, file_path='./best_model',\n            writer=None\n            ):\n    \n    best_acc_val = 0\n    print(\"Start training...\\n\")\n    for epoch_i in range(epochs):\n        # =======================================\n        #               Training\n        # =======================================\n        \n\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*100)\n\n        \n        t0_epoch, t0_batch = time.time(), time.time()\n\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        \n        model.train()\n\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n\n            img_ip , text_ip, label = batch[\"image_id\"], batch[\"BERT_ip\"], batch['label']\n            \n            b_input_ids, b_attn_mask = tuple(t.to(device) for t in text_ip)\n            \n            imgs_ip = img_ip.to(device)\n            \n            b_labels = label.to(device)\n\n            \n            model.zero_grad()\n\n            \n            # logits, att_mask_img = model(text=[b_input_ids, b_attn_mask], image=imgs_ip, label=b_labels)\n            logits = model(text=[b_input_ids, b_attn_mask], image=imgs_ip)\n\n            b_labels=b_labels.to(torch.float32)\n            loss = loss_fn(logits, b_labels)\n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n            \n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            \n            optimizer.step()\n            scheduler.step()\n\n\n            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                time_elapsed = time.time() - t0_batch\n\n                \n                print(f\"epoch{epoch_i + 1:^7} | batch{step:^7} | loss{batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | elapsed{time_elapsed:^9.2f}\")\n                \n                \n                if writer != None:\n                    writer.add_scalar('Training Loss', (batch_loss / batch_counts), epoch_i*len(train_dataloader)+step)\n                \n                \n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n       \n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"-\"*100)\n\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            \n            val_loss, val_accuracy = evaluate(model, loss_fn, val_dataloader, device)\n            \n            time_elapsed = time.time() - t0_epoch\n            print(f\" {epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            print(\"-\"*70)\n            \n            if writer != None:\n                writer.add_scalar('Validation Loss', val_loss, epoch_i+1)\n                writer.add_scalar('Validation Accuracy', val_accuracy, epoch_i+1)\n            \n            \n            if save_best: \n                \n                if val_accuracy > best_acc_val:\n                    best_acc_val = val_accuracy\n                    torch.save({\n                                'epoch': epoch_i+1,\n                                'model_params': param_dict_model,\n                                'opt_params': param_dict_opt,\n                                'model_state_dict': model.state_dict(),\n                                'opt_state_dict': optimizer.state_dict(),\n                                'sch_state_dict': scheduler.state_dict()\n                               }, file_path)\n                    \n        print(\"\\n\")\n    \n    print(\"Training complete!\")\n    \n    \ndef evaluate(model, loss_fn, val_dataloader, device):\n   \n\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n\n    for batch in val_dataloader:\n        img_ip , text_ip, label = batch[\"image_id\"], batch[\"BERT_ip\"], batch['label']\n            \n        b_input_ids, b_attn_mask = tuple(t.to(device) for t in text_ip)\n\n        imgs_ip = img_ip.to(device)\n\n        b_labels = label.to(device)\n\n    \n        with torch.no_grad():\n            # logits, att_mask_img = model(text=[b_input_ids, b_attn_mask], image=imgs_ip, label=b_labels)\n            logits = model(text=[b_input_ids, b_attn_mask], image=imgs_ip)\n            b_labels=b_labels.to(torch.float32)\n            \n        \n        loss = loss_fn(logits, b_labels)\n        val_loss.append(loss.item())\n\n        logits[logits<0.5] = 0\n        logits[logits>=0.5] = 1\n        # print(logits)\n        #\n        # preds = torch.argmax(logits, dim=1).flatten()\n        #print(preds)\n\n        \n        accuracy = (logits == b_labels).cpu().numpy().mean() * 100\n        val_accuracy.append(accuracy)\n       \n\n    \n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n    \n\n    return val_loss, val_accuracy","metadata":{"id":"HB5TkDUqfxtY","execution":{"iopub.status.busy":"2022-04-20T04:07:47.241902Z","iopub.execute_input":"2022-04-20T04:07:47.242202Z","iopub.status.idle":"2022-04-20T04:07:51.3135Z","shell.execute_reply.started":"2022-04-20T04:07:47.242165Z","shell.execute_reply":"2022-04-20T04:07:51.312787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# main","metadata":{"id":"9wZuO1JrRRFy"}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import AdamW\nimport random\nimport time\nimport os\nimport re\nimport math\n\nfrom torch.utils.tensorboard import SummaryWriter\n\n\n#tesing.............................\n\nfrom importlib_metadata import re\nimport torch\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import models, transforms\nimport torch.nn as nn\nfrom transformers import BertModel\n\ndevice = torch.device(\"cuda\")\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\n\nimport torch.nn.functional as F\nfrom transformers import BertModel\nimport random\nimport time\nimport os\nimport re\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport torchvision\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport random\nimport time\nimport os\nimport re\nimport math\n\n#from models import *\n#from data_loader import *\n#from train_val import *\n\n\ndf_train = pd.read_csv(\"../input/fakenews/SpotFake_Implemetation-master/twitter/train_posts_clean.csv\")\ndf_test = pd.read_csv(\"../input/fakenews/SpotFake_Implemetation-master/twitter/test_posts.csv\")\n\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n    \n\nimage_transform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize(size=(224, 224)),\n        torchvision.transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]\n)\n\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n\n\nMAX_LEN = 500\nroot_dir = \"../input/fakenews/SpotFake_Implemetation-master/twitter/\"\n\n\ntransformed_dataset_train = FakeNewsDataset(df_train, root_dir+\"images_train/\", image_transform, tokenizer, MAX_LEN)\n\ntransformed_dataset_val = FakeNewsDataset(df_test, root_dir+\"images_test/\", image_transform, tokenizer, MAX_LEN)\n\ntrain_dataloader = DataLoader(transformed_dataset_train, batch_size=8,\n                        shuffle=True, num_workers=0)\n\nval_dataloader = DataLoader(transformed_dataset_val, batch_size=8,\n                        shuffle=True, num_workers=0)\n\n\n\nloss_fn = nn.BCELoss()\n\ndef set_seed(seed_value=42):\n    \n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\nparameter_dict_model={\n    'text_fc2_out': 32, \n    'text_fc1_out': 2742, \n    'dropout_p': 0.4, \n    'fine_tune_text_module': False,\n    'img_fc1_out': 2742, \n    'img_fc2_out': 32, \n    'dropout_p': 0.4, \n    'fine_tune_vis_module': False,\n    'fusion_output_size': 35,\n    'no_deprecation_warning':True\n    }\n\nparameter_dict_opt={'l_r': 3e-5,\n                    'eps': 1e-8\n                    }\n\n\nEPOCHS=50\n\n# 设置随机种子\nset_seed(7)\n\nfinal_model = Text_Concat_Vision(parameter_dict_model)\n\nfinal_model = final_model.to(device) \n\n\noptimizer = AdamW(final_model.parameters(),\n                  lr=parameter_dict_opt['l_r'],\n                  eps=parameter_dict_opt['eps'])\n\n\ntotal_steps = len(train_dataloader) * EPOCHS\n\n\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps=0, # 默认值\n                                            num_training_steps=total_steps)\n\n\nwriter = SummaryWriter('./summary')\n\n\ntrain(model=final_model,\n      loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n      train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n      epochs=15, evaluation=True,\n      device=device,\n      param_dict_model=parameter_dict_model, param_dict_opt=parameter_dict_opt,\n      save_best=True,\n      file_path='./best_model.pt', \n      writer=writer\n      )","metadata":{"id":"DitN-Di5RQJj","outputId":"a97552a9-dbcd-4596-f26f-230b31e62bf9","execution":{"iopub.status.busy":"2022-04-20T04:07:51.314956Z","iopub.execute_input":"2022-04-20T04:07:51.315231Z","iopub.status.idle":"2022-04-20T06:35:33.654608Z","shell.execute_reply.started":"2022-04-20T04:07:51.315195Z","shell.execute_reply":"2022-04-20T06:35:33.653822Z"},"trusted":true},"execution_count":null,"outputs":[]}]}